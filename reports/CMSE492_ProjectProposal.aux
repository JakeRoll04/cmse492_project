\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background and Motivation}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Description}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Preprocessing}{2}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Distributions of key numeric features (e.g., age, hours-per-week, capital gain).}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:distributions}{{1}{3}{Distributions of key numeric features (e.g., age, hours-per-week, capital gain)}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Class balance for the binary income target (\texttt  {<=50K} vs \texttt  {>50K}).}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:classbalance}{{2}{3}{Class balance for the binary income target (\texttt {<=50K} vs \texttt {>50K})}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Proposed Methodology}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Machine Learning Task and Objective}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Type of Machine Learning Task}{5}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Models}{5}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Logistic Regression (Baseline Model)}{6}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Random Forest (Intermediate Complexity)}{6}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Gradient Boosting (Advanced Model)}{6}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Model Parameters, Loss Functions, and Regularization}{6}{subsection.6.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Model parameters, hyperparameters, loss functions, and regularization for the classifiers.}}{6}{table.1}\protected@file@percent }
\newlabel{tab:model-specification}{{1}{6}{Model parameters, hyperparameters, loss functions, and regularization for the classifiers}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Training Methodology}{7}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Loss Functions}{7}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Tracking Learning and Avoiding Overfitting}{7}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Hyperparameter Tuning and Learning Curves}{7}{subsection.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gradient Boosting learning curve showing training and validation accuracy as a function of the number of boosting stages.}}{8}{figure.3}\protected@file@percent }
\newlabel{fig:gb-learning-curve}{{3}{8}{Gradient Boosting learning curve showing training and validation accuracy as a function of the number of boosting stages}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Hyperparameter Tuning}{8}{subsection.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Evaluation Metrics}{8}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Accuracy.}{9}{paragraph*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Precision.}{9}{paragraph*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Recall.}{9}{paragraph*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{F1 Score.}{9}{paragraph*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary.}{9}{paragraph*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Results and Model Comparison}{9}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Model Performance}{9}{subsection.9.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Validation set comparison of the three classifiers. Metrics are shown for the minority \texttt  {>50K} income class.}}{10}{table.2}\protected@file@percent }
\newlabel{tab:metric-comparison}{{2}{10}{Validation set comparison of the three classifiers. Metrics are shown for the minority \texttt {>50K} income class}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Training and Inference Time}{10}{subsection.9.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Training and inference times for each model. (Values depend on hardware.)}}{10}{table.3}\protected@file@percent }
\newlabel{tab:time-comparison}{{3}{10}{Training and inference times for each model. (Values depend on hardware.)}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Error Analysis}{10}{subsection.9.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Confusion matrix for the Gradient Boosting model on the test set.}}{11}{figure.4}\protected@file@percent }
\newlabel{fig:gb-confusion-matrix}{{4}{11}{Confusion matrix for the Gradient Boosting model on the test set}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Why the Models Perform Differently}{11}{subsection.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}Choice of Best Model}{12}{subsection.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Model Interpretation}{12}{section.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Top 20 Gradient Boosting feature importances on the one-hot encoded Adult dataset.}}{13}{figure.5}\protected@file@percent }
\newlabel{fig:gb-feature-importance}{{5}{13}{Top 20 Gradient Boosting feature importances on the one-hot encoded Adult dataset}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Interpretation Summary}{13}{subsection.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Recursive Feature Elimination (RFE) with logistic regression, showing the most important encoded features.}}{14}{figure.6}\protected@file@percent }
\newlabel{fig:rfe-logreg}{{6}{14}{Recursive Feature Elimination (RFE) with logistic regression, showing the most important encoded features}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces SHAP summary plot for the Gradient Boosting model, showing the contribution of encoded features to predicting \texttt  {>50K} income.}}{15}{figure.7}\protected@file@percent }
\newlabel{fig:shap-summary}{{7}{15}{SHAP summary plot for the Gradient Boosting model, showing the contribution of encoded features to predicting \texttt {>50K} income}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Conclusion}{16}{section.11}\protected@file@percent }
\gdef \@abspage@last{16}
